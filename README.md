# Linux for Data Engineering - Learning Roadmap

This repository provides a **step-by-step roadmap to learn Linux for Data Engineering**. The goal is to acquire practical skills to manage, process, and automate data workflows on Linux servers, which are widely used in production data engineering environments.

---

## ðŸ“‚ Project Folder Structure

![Description of Image](2025-08-20-033324.png)

---

#### ðŸ“… Step-by-Step Learning Roadmap

| Step | Topics                          | Skills & Practical Exercises                                 |
| ---- | ------------------------------- | ------------------------------------------------------------ |
| 1    | **Linux Basics**                | Understand the Linux filesystem, navigate directories, create/remove files, copy/move files, and use basic commands (`ls`, `cd`, `pwd`, `mkdir`, `touch`). Hands-on exercises: create folders and files, practice navigation. |
| 2    | **File Management & Users**     | Learn file permissions, ownership, groups, user creation, and sudo privileges. Hands-on exercises: manage users and groups, set file/folder permissions, compress and transfer files using `tar`, `gzip`, `scp`, and `rsync`. |
| 3    | **Data Processing**             | Learn to process text and structured data using `grep`, `awk`, `sed`, `cut`, and `sort`. Hands-on exercises: extract and filter data from CSV or log files, perform column-based operations. |
| 4    | **Scripting & Automation**      | Write reusable Bash scripts and automate repetitive tasks. Learn `cron` jobs to schedule scripts. Hands-on exercises: create scripts to process multiple files automatically and schedule them via cron. |
| 5    | **Process & System Monitoring** | Learn to monitor system processes, memory, and disk usage (`ps`, `top`, `htop`, `df`, `du`, `free`). Hands-on exercises: monitor services, manage background processes, and log system resource usage. |
| 6    | **Networking & Remote Access**  | Access remote servers via `ssh`, transfer files using `scp` or `rsync`. Learn basic networking commands (`ping`, `traceroute`, `curl`, `wget`). Hands-on exercises: transfer files between local and remote servers, execute commands remotely. |
| 7    | **Data Engineering Tools**      | Install and run Docker containers, manage images and volumes. Install and configure Apache Airflow, create DAGs for data pipelines. Hands-on exercises: build a Docker container for a data workflow, run an example Airflow DAG. |
| 8    | **Final Project**               | Apply all skills to build a **complete data processing pipeline**. Steps include: collecting data, processing data with Bash scripts, storing processed files, and scheduling automated tasks. Hands-on exercises: final project scripts in `step8_project/scripts`, input data in `data/`, and output files in `output/`. |

---

#### ðŸ’¡ Key Tips

- Practice **hands-on exercises** for each step to reinforce learning.
- Keep all scripts and datasets organized inside **exercises** and **step8_project** folders.
- Use **VMs, WSL, or Docker** to simulate real Linux environments.
- Document commands, scripts, and lessons learned in **notes.txt** files.
- The final project should combine **data collection, processing, storage, and scheduling**.

---

### ðŸ”— Recommended Resources

- [Linux Command Line Basics](https://linuxcommand.org/) â€“ Beginner-friendly tutorials.
- [Bash Scripting Tutorial](https://ryanstutorials.net/bash-scripting-tutorial/) â€“ Step-by-step scripting guide.
- [Docker Documentation](https://docs.docker.com/) â€“ Learn containerization for data workflows.
- [Apache Airflow Documentation](https://airflow.apache.org/docs/) â€“ Official Airflow guide for building DAGs.
- [Linux System Monitoring](https://www.tecmint.com/linux-monitoring-commands/) â€“ Monitor processes, disk, and memory.

This version:

- Provides **detailed descriptions** for each step.
- Explains **what skills will be gained**.
- Suggests **practical exercises** clearly.
- Makes it **GitHub-ready** and easy for learners to follow.

```
linux-data-engineering/
 â”‚
 â”œâ”€â”€ step1_basics/
 â”‚   â”œâ”€â”€ commands.md                # Core Linux commands (ls, cd, pwd, cp, mv, rm, mkdir, etc.)
 â”‚   â”œâ”€â”€ exercises/
 â”‚   â”‚   â”œâ”€â”€ create_files.sh        # Practice creating, renaming, and deleting files/folders
 â”‚   â”‚   â””â”€â”€ navigate_directories.sh
 â”‚   â””â”€â”€ notes.txt                  # Key notes, tips, and shortcuts
 â”‚
 â”œâ”€â”€ step2_file_user_management/
 â”‚   â”œâ”€â”€ permissions.md             # File and folder permissions, chmod, chown, ACLs
 â”‚   â”œâ”€â”€ users_groups.md            # Users, groups, sudo, and user management
 â”‚   â””â”€â”€ exercises/
 â”‚       â””â”€â”€ compress_transfer_files.sh  # Practice tar, gzip, scp, rsync
 â”‚
 â”œâ”€â”€ step3_data_processing/
 â”‚   â”œâ”€â”€ grep_awk_sed.md            # Text processing tools for logs and CSV files
 â”‚   â”œâ”€â”€ csv_processing_examples.sh
 â”‚   â””â”€â”€ exercises/
 â”‚       â””â”€â”€ extract_filter_data.sh
 â”‚
 â”œâ”€â”€ step4_scripting_automation/
 â”‚   â”œâ”€â”€ bash_scripting.md          # Writing reusable Bash scripts
 â”‚   â”œâ”€â”€ cron_jobs.md               # Scheduling scripts and automation
 â”‚   â””â”€â”€ exercises/
 â”‚       â””â”€â”€ batch_process_csv.sh
 â”‚
 â”œâ”€â”€ step5_process_monitoring/
 â”‚   â”œâ”€â”€ processes.md               # ps, top, htop, kill, jobs, background processes
 â”‚   â”œâ”€â”€ disk_memory.md             # df, du, free, iostat, monitoring disk/memory usage
 â”‚   â””â”€â”€ exercises/
 â”‚       â””â”€â”€ monitor_services.sh
 â”‚
 â”œâ”€â”€ step6_networking/
 â”‚   â”œâ”€â”€ ssh_scp.md                 # Remote access and file transfer
 â”‚   â”œâ”€â”€ networking_commands.md     # netstat, ping, traceroute, curl, wget
 â”‚   â””â”€â”€ exercises/
 â”‚       â””â”€â”€ remote_file_transfer.sh
 â”‚
 â”œâ”€â”€ step7_data_engineering_tools/
 â”‚   â”œâ”€â”€ docker.md                  # Introduction to Docker for containerized environments
 â”‚   â”œâ”€â”€ airflow.md                 # Installing and running Airflow, DAG examples
 â”‚   â””â”€â”€ exercises/
 â”‚       â””â”€â”€ airflow_dag_example.py
 â”‚
 â”œâ”€â”€ step8_project/
 â”‚   â”œâ”€â”€ README.md                  # Project description and instructions
 â”‚   â”œâ”€â”€ data/
 â”‚   â”‚   â””â”€â”€ sample_data.csv
 â”‚   â”œâ”€â”€ scripts/
 â”‚   â”‚   â””â”€â”€ process_data.sh        # Final project data processing scripts
 â”‚   â””â”€â”€ output/
 â”‚       â””â”€â”€ processed_data.csv     # Output of final project
 â”‚
 â””â”€â”€ README.md
```
